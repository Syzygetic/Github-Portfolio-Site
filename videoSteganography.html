<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Video Steganography — In-browser (LSB RGB)</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" />
  <style>
    body { background:#f0f8ff; color:#333; }
    .navbar { background:#e0f0ff; }
    .card { border-radius:1rem; box-shadow:0 4px 10px rgba(0,0,0,0.05); }
    .btn-primary { background:#5dade2; border-color:#5dade2; }
    .btn-primary:hover { background:#3498db; }
    #progressContainer { display:none; margin-top:1rem; }
    #statusText { white-space:pre-line; }
    canvas { max-width:100%; }
  </style>
</head>
<body>
  <nav class="navbar navbar-expand-lg mb-4">
    <div class="container-fluid">
      <a class="navbar-brand fw-bold" href="index.html">MySite</a>
    </div>
  </nav>

  <div class="container">
    <h1 class="text-center mb-4">Video Steganography (LSB RGB, in-browser)</h1>

    <div class="card p-4 mb-4">
      <div class="mb-3">
        <label class="form-label">Upload Video</label>
        <input id="videoInput" type="file" class="form-control" accept="video/*">
      </div>

      <div class="row g-2 mb-3">
        <div class="col-md-9">
          <label class="form-label">Secret message to hide</label>
          <textarea id="secretMessage" rows="3" class="form-control"></textarea>
        </div>
        <div class="col-md-3">
          <label class="form-label">BitRange (bits / channel)</label>
          <select id="bitRange" class="form-select">
            <option value="1">1</option>
            <option value="2">2</option>
            <option value="3">3</option>
            <option value="4" selected>4</option>
            <option value="5">5</option>
            <option value="6">6</option>
            <option value="7">7</option>
            <option value="8">8</option>
          </select>
          <div class="small text-muted mt-2">Total bits/pixel = bitRange × 3</div>
        </div>
      </div>

      <div class="d-flex gap-2">
        <button id="encodeBtn" class="btn btn-primary" disabled>Encode Message (steganography)</button>
        <button id="cancelBtn" class="btn btn-secondary" disabled>Cancel</button>
        <div id="capacityInfo" class="ms-3 align-self-center small text-muted"></div>
      </div>

      <div id="progressContainer" class="mt-3">
        <div class="progress">
          <div id="progressBar" class="progress-bar" role="progressbar" style="width:0%">0%</div>
        </div>
        <div id="statusText" class="mt-2"></div>
      </div>
    </div>

    <div id="previewArea" class="text-center" style="display:none;">
      <h5>Preview (first frame)</h5>
      <canvas id="frameCanvas" style="border:1px solid #ddd;"></canvas>
    </div>
  </div>

  <!-- FFmpeg.js -->
  <script src="./assets/ffmpeg/umd/ffmpeg.js"></script>

  <script>
  document.addEventListener('DOMContentLoaded', () => {
    const videoInput = document.getElementById('videoInput');
    const secretMessage = document.getElementById('secretMessage');
    const bitRangeSelect = document.getElementById('bitRange');
    const encodeBtn = document.getElementById('encodeBtn');
    const cancelBtn = document.getElementById('cancelBtn');
    const capacityInfo = document.getElementById('capacityInfo');
    const progressContainer = document.getElementById('progressContainer');
    const progressBar = document.getElementById('progressBar');
    const statusText = document.getElementById('statusText');
    const previewArea = document.getElementById('previewArea');
    const frameCanvas = document.getElementById('frameCanvas');
    const ctx = frameCanvas.getContext('2d');

    const ffmpeg = new FFmpegWASM.FFmpeg({
      log: true,
      corePath: './assets/ffmpeg/ffmpeg-core.wasm',
      workerPath: './assets/ffmpeg/esm/worker.js'
    });

    let canceled = false;
    let ffmpegLoaded = false;

    cancelBtn.addEventListener('click', () => {
      canceled = true;
      statusText.textContent = 'Cancel requested — terminating ffmpeg...';
      try { ffmpeg.terminate(); } catch(e){ console.warn('terminate failed', e); }
      cancelBtn.disabled = true;
    });

    async function loadFFmpeg() {
      if (!ffmpegLoaded) {
        statusText.textContent = 'Loading FFmpeg-wasm...';
        await ffmpeg.load();
        ffmpegLoaded = true;
        statusText.textContent = 'FFmpeg loaded.';
      }
    }

    function pad(n,digits=5){ return String(n).padStart(digits,'0'); }
    function messageToBinary(msg){ return (msg+'=====').split('').map(c=>c.charCodeAt(0).toString(2).padStart(8,'0')).join(''); }
    function writeBitsToChannel(channelVal,bits,bitRange){
      const origLen = bits.length;
      if(bits.length<bitRange) bits += '0'.repeat(bitRange-bits.length);
      const bin = channelVal.toString(2).padStart(8,'0');
      const newBin = bin.slice(0, 8-bitRange) + bits;
      return { newVal: parseInt(newBin,2), consumed: origLen };
    }

    // Probe function using ffprobe if available; otherwise fallback to extracting first frame
    async function probeVideoMeta(fileBuffer) {
      // fileBuffer: Uint8Array of input.mp4
      // write input and ffprobe
      await ffmpeg.writeFile('input.mp4', fileBuffer);
      let info = null;
      try {
        info = await ffmpeg.ffprobe('input.mp4');
      } catch(e){
        // ffprobe may still throw; we'll fallback later to extracting first frame
        info = null;
      }
      let duration = 0, fps = 25, width = null, height = null;
      if(info && info.format) {
        duration = parseFloat(info.format.duration || 0) || 0;
        const vstream = (info.streams||[]).find(s=>s.codec_type==='video');
        if(vstream){
          if(vstream.avg_frame_rate && vstream.avg_frame_rate.includes('/')){
            const [num,den] = vstream.avg_frame_rate.split('/').map(Number);
            if(den) fps = num/den;
          } else if(vstream.r_frame_rate){
            const [num,den] = String(vstream.r_frame_rate).split('/').map(Number);
            if(den) fps = num/den;
          }
          if(vstream.width) width = vstream.width;
          if(vstream.height) height = vstream.height;
        }
      }

      // If width/height missing, extract first frame to determine resolution
      if(!width || !height){
        try{
          await ffmpeg.exec(['-i','input.mp4','-ss','00:00:00','-frames:v','1','probe_f000.png']);
          const f0 = await ffmpeg.readFile('probe_f000.png');
          const imgBlob = new Blob([f0.buffer],{type:'image/png'});
          const img = new Image();
          await new Promise((res,rej)=>{ img.onload=res; img.onerror=rej; img.src=URL.createObjectURL(imgBlob); });
          width = img.width; height = img.height;
          // delete probe file to keep FS light
          try{ await ffmpeg.deleteFile('probe_f000.png'); } catch(e){}
        } catch(e){}
      }

      return { duration, fps, width, height };
    }

    async function generatePreviewAndEstimate(file){
      statusText.textContent=''; capacityInfo.textContent=''; previewArea.style.display='none';
      await loadFFmpeg();
      const arr = await file.arrayBuffer();
      const u8 = new Uint8Array(arr);
      statusText.textContent='Probing video metadata...';
      const meta = await probeVideoMeta(u8);
      const duration = meta.duration || 0;
      const fps = meta.fps || 25;
      const fpsUsed = Math.max(1, Math.floor(fps));

      // extract first frame and show preview
      await ffmpeg.exec(['-i','input.mp4','-ss','00:00:00','-frames:v','1','f000.png']);
      const f0 = await ffmpeg.readFile('f000.png');
      const imgBlob = new Blob([f0.buffer],{type:'image/png'});
      const img = new Image();
      await new Promise((res,rej)=>{ img.onload=res; img.onerror=rej; img.src=URL.createObjectURL(imgBlob); });
      frameCanvas.width=img.width; frameCanvas.height=img.height;
      ctx.drawImage(img,0,0);
      previewArea.style.display='block';

      // compute capacity
      const bitRange=parseInt(bitRangeSelect.value,10);
      const bitsPerFrame = img.width*img.height*3*bitRange;
      const estFrames=Math.max(1,Math.round(duration*fpsUsed));
      const totalCapacityBits=bitsPerFrame*estFrames;
      capacityInfo.textContent=`Resolution ${img.width}×${img.height} | est frames ${estFrames} | capacity ≈ ${Math.floor(totalCapacityBits/8)} bytes (${totalCapacityBits} bits)`;
      statusText.textContent=`Detected duration ${duration.toFixed(2)}s, fps ≈ ${fpsUsed}.`;

      // keep input.mp4 in FS for later (already written by probeVideoMeta)
    }

    // main encode function: 2-pass safe remux, Merge-Strict, unique filenames, fail on overflow
    async function encodeSteg(file, message){
      canceled=false; cancelBtn.disabled=false; encodeBtn.disabled=true;
      progressContainer.style.display='block';
      progressBar.style.width='0%'; progressBar.textContent='0%';
      statusText.textContent='Preparing...';

      // unique run prefix
      const runPrefix = 'run_' + Date.now();
      const framePattern = `${runPrefix}_frame%05d.png`;
      const frameName = (i)=>`${runPrefix}_frame${pad(i)}.png`;

      let terminatedFFmpegAfter = false;

      try{
        await loadFFmpeg();

        // load file into worker FS once
        const arr = await file.arrayBuffer();
        const inU8 = new Uint8Array(arr);
        await ffmpeg.writeFile('input.mp4', inU8);

        statusText.textContent='Probing video metadata...';
        const meta = await probeVideoMeta(inU8);
        const duration = meta.duration || 0;
        const fps = meta.fps || 25;
        const width = meta.width;
        const height = meta.height;
        const fpsUsed = Math.max(1, Math.round(fps));
        const totalFrames = Math.max(1, Math.round(duration*fpsUsed));
        statusText.textContent=`Video duration: ${duration}s | fps≈${fpsUsed} | frames≈${totalFrames}`;

        // Determine resolution reliably (from metadata or first frame)
        let w = width, h = height;
        if(!w || !h){
          // extract first frame
          await ffmpeg.exec(['-i','input.mp4','-ss','00:00:00','-frames:v','1','probe_f000.png']);
          const p0 = await ffmpeg.readFile('probe_f000.png');
          const imgBlob = new Blob([p0.buffer],{type:'image/png'});
          await new Promise((res,rej)=>{
            const img = new Image();
            img.onload = ()=>{ w = img.width; h = img.height; res(); };
            img.onerror = rej;
            img.src = URL.createObjectURL(imgBlob);
          });
          try{ await ffmpeg.deleteFile('probe_f000.png'); } catch(e){}
        }

        if(!w || !h) throw new Error('Could not determine video resolution');

        const bitRange = parseInt(bitRangeSelect.value,10);
        const bitsPerFrame = w*h*3*bitRange;
        const capacityBits = bitsPerFrame * totalFrames;
        const binary = messageToBinary(message);

        // fail on overflow
        if(binary.length > capacityBits){
          throw new Error(`Message too large: requires ${binary.length} bits but capacity is ${capacityBits} bits.`);
        }

        // Extract audio strictly (Merge-Strict). We'll try to copy audio stream first; if fails, try re-encode; but if no audio, fail.
        statusText.textContent='Extracting audio (merge-strict)...';
        let haveAudio = false;
        try{
          // Try to copy audio track
          await ffmpeg.exec(['-i','input.mp4','-vn','-acodec','copy','extracted_audio']);
          // If succeeded, file may be created.
          try{ await ffmpeg.readFile('extracted_audio'); haveAudio = true; } catch(e){ haveAudio = false; }
        } catch(e){
          // copy failed — try re-encode to mp3 as fallback (still counts as "audio present" if succeeds)
          try{
            await ffmpeg.exec(['-i','input.mp4','-vn','-q:a','0','extracted_audio.mp3']);
            try{ await ffmpeg.readFile('extracted_audio.mp3'); haveAudio = true; } catch(e2){ haveAudio = false; }
          } catch(e2){
            haveAudio = false;
          }
        }
        if(!haveAudio){
          throw new Error('Merge-Strict: input has no audio track (or extraction failed). Aborting.');
        }

        // Process frames (sequential, small batches)
        statusText.textContent='Embedding message into frames...';
        let bitIndex = 0;
        const BATCH_SIZE = 4; // keep small to reduce memory pressure

        for(let batchStart=0; batchStart<totalFrames; batchStart+=BATCH_SIZE){
          if(canceled) throw new Error('Encoding canceled by user');
          const batchEnd = Math.min(batchStart + BATCH_SIZE, totalFrames);

          for(let i=batchStart;i<batchEnd;i++){
            const ts = (i/fpsUsed).toFixed(3);
            const fname = frameName(i);

            // extract single frame into FS as fname (unique)
            await ffmpeg.exec(['-i','input.mp4','-ss',ts,'-frames:v','1',fname]);

            // read that file and load into image
            const fdata = await ffmpeg.readFile(fname);
            const imgBlob = new Blob([fdata.buffer],{type:'image/png'});

            await new Promise((res,rej)=>{
              const img = new Image();
              const url = URL.createObjectURL(imgBlob);
              img.onload = async ()=>{
                try{
                  URL.revokeObjectURL(url);
                  frameCanvas.width = img.width;
                  frameCanvas.height = img.height;
                  ctx.drawImage(img,0,0);
                  // embed bits into canvas image data
                  const imageData = ctx.getImageData(0,0,frameCanvas.width,frameCanvas.height);
                  const data = imageData.data;
                  for(let p=0;p<data.length && bitIndex<binary.length;p+=4){
                    for(let c=0;c<3 && bitIndex<binary.length;c++){
                      const chunk = binary.slice(bitIndex, bitIndex + bitRange);
                      const {newVal, consumed} = writeBitsToChannel(data[p+c], chunk, bitRange);
                      data[p+c] = newVal;
                      bitIndex += consumed;
                    }
                  }
                  ctx.putImageData(imageData,0,0);

                  // write edited frame back into FFmpeg FS (overwrite)
                  frameCanvas.toBlob(async (b)=>{
                    try{
                      const ab = await b.arrayBuffer();
                      await ffmpeg.writeFile(fname, new Uint8Array(ab));
                      res();
                    } catch(err){
                      rej(err);
                    }
                  }, 'image/png');
                } catch(err){ rej(err); }
              };
              img.onerror = rej;
              img.src = url;
            });

            // update per-frame progress
            const percent = Math.round(((i+1)/totalFrames)*100);
            progressBar.style.width = percent + '%';
            progressBar.textContent = `${percent}% (${i+1}/${totalFrames})`;
            statusText.textContent = `Embedding frames — processed ${i+1}/${totalFrames}, bits used ${bitIndex}/${binary.length}`;
          } // end inner for
        } // end batches loop

        if(bitIndex < binary.length){
          throw new Error(`Unexpected: not all bits embedded (used ${bitIndex} of ${binary.length}).`);
        }

        // Re-encode frames into video (no audio)
        statusText.textContent = 'Re-encoding frames into video (no audio)...';
        // use pattern with prefix created earlier
        await ffmpeg.exec(['-framerate', String(fpsUsed), '-i', framePattern, '-c:v', 'libx264', '-pix_fmt', 'yuv420p', 'video_no_audio.mp4']);

        // Merge audio back (strict): try copy audio stream first, fallback to re-encode input audio stream format if needed.
        statusText.textContent = 'Merging audio (strict)...';
        // determine which extracted audio file exists
        let audioName = null;
        try { await ffmpeg.readFile('extracted_audio'); audioName = 'extracted_audio'; } catch(e){}
        if(!audioName){
          try{ await ffmpeg.readFile('extracted_audio.mp3'); audioName = 'extracted_audio.mp3'; } catch(e){}
        }
        if(!audioName){
          // We expected earlier haveAudio true; if not found, fail
          throw new Error('Merge-Strict: extracted audio not found — aborting.');
        }

        // Try remux (copy) first
        try {
          await ffmpeg.exec(['-i','video_no_audio.mp4','-i',audioName,'-c','copy','stego_output.mp4']);
        } catch(errRemux){
          // If copy fails, try re-encoding audio to aac and then merge
          try {
            await ffmpeg.exec(['-i', audioName, '-c:a', 'aac', '-b:a','128k','tmp_audio_aac.m4a']);
            await ffmpeg.exec(['-i','video_no_audio.mp4','-i','tmp_audio_aac.m4a','-c:v','copy','-c:a','copy','stego_output.mp4']);
          } catch(e2){
            throw new Error('Merge failed: unable to merge audio back into video.');
          }
        }

        // read output
        statusText.textContent = 'Packaging output...';
        const out = await ffmpeg.readFile('stego_output.mp4');
        const outBlob = new Blob([out.buffer], {type:'video/mp4'});
        const url = URL.createObjectURL(outBlob);
        const a = document.createElement('a');
        a.href = url;
        a.download = 'stego_encoded_video.mp4';
        a.textContent = 'Download encoded video';
        a.className = 'btn btn-success mt-2';
        statusText.textContent = 'Encoding complete — download below.';
        statusText.appendChild(document.createElement('br'));
        statusText.appendChild(a);

        // Clean up temporary frame files & intermediates to avoid leaving many files in FS.
        statusText.textContent = 'Cleaning up temporary files...';
        try {
          // delete frames
          for(let i=0;i<totalFrames;i++){
            try{ await ffmpeg.deleteFile(frameName(i)); } catch(e){}
          }
          // delete intermediates
          try{ await ffmpeg.deleteFile('video_no_audio.mp4'); } catch(e){}
          try{ await ffmpeg.deleteFile('stego_output.mp4'); } catch(e){}
          try{ await ffmpeg.deleteFile('input.mp4'); } catch(e){}
          try{ await ffmpeg.deleteFile('extracted_audio'); } catch(e){}
          try{ await ffmpeg.deleteFile('extracted_audio.mp3'); } catch(e){}
          try{ await ffmpeg.deleteFile('tmp_audio_aac.m4a'); } catch(e){}
        } catch(e){
          // ignore cleanup errors, we'll terminate worker next
        }

        progressBar.style.width='100%';
        progressBar.textContent='100%';

        // Immediately terminate ffmpeg worker to release memory (C1)
        try { ffmpeg.terminate(); terminatedFFmpegAfter = true; } catch(e){ console.warn('terminate failed', e); }

      } catch(err){
        console.error('Encoding error:', err);
        statusText.textContent = 'Error: ' + (err?.message || String(err));
      } finally {
        if(!terminatedFFmpegAfter){
          // ensure UI state reset even if we didn't terminate above
          try { /* don't auto-terminate here if user wants to reuse ffmpeg; but C1 wanted immediate terminate */ } catch(e){}
        }
        encodeBtn.disabled = false;
        cancelBtn.disabled = true;
      }
    }

    videoInput.addEventListener('change', async ()=>{
      capacityInfo.textContent=''; statusText.textContent=''; progressContainer.style.display='none'; encodeBtn.disabled=true;
      try{
        const file = videoInput.files[0]; if(!file) return;
        await generatePreviewAndEstimate(file);
        encodeBtn.disabled=false;
      } catch(e){ console.error(e); statusText.textContent='Preview failed: '+(e.message||e); }
    });

    encodeBtn.addEventListener('click', async ()=>{
      const file = videoInput.files[0]; const msg = secretMessage.value || '';
      if(!file){ alert('Select a video'); return; }
      if(!msg){ alert('Type a secret message'); return; }
      encodeBtn.disabled=true;
      await encodeSteg(file,msg);
    });

  });
  </script>
</body>
</html>
